Voici un **README.md** professionnel, structur√© et pr√™t √† l'emploi pour ton d√©p√¥t GitHub. Il met en valeur ta d√©marche analytique, l'utilisation des concepts de tes cours et les r√©sultats concrets obtenus sur le dataset SECOM.

---

# üöÄ SECOM Predictive Maintenance: Yield Analysis

Ce projet applique des techniques avanc√©es de **Machine Learning** pour pr√©dire les d√©fauts de fabrication dans l'industrie des semi-conducteurs. √Ä partir de 591 capteurs (dataset SECOM), l'objectif est d'identifier les puces non-conformes dans un environnement fortement d√©s√©quilibr√©.

## üìå Points Cl√©s du Projet

* **D√©tection des pannes :** Passage d'un rappel (recall) de **19% √† 62%**.
* **Interpr√©tabilit√© :** Identification des 5 capteurs les plus critiques via les Odds Ratios.
* **Ma√Ætrise de l'imbalance :** Mise en ≈ìuvre du SMOTE et du r√©-√©chantillonnage stratifi√©.

---

## üõ†Ô∏è M√©thodologie & Pipeline (Slide 12)

Le projet suit un pipeline rigoureux d√©velopp√© avec `imbalanced-learn` pour garantir l'absence de fuite de donn√©es (*data leakage*) :

1. **Data Cleaning :** Suppression des colonnes constantes (sans variance).
2. **Preprocessing :** Imputation des valeurs manquantes par la **m√©diane** et **Standardisation** (-score).
3. **Gestion du d√©s√©quilibre :** Application du **SMOTE** (Synthetic Minority Over-sampling Technique) pour √©quilibrer les classes.
4. **Feature Selection :** S√©lection des **40 meilleurs signaux** via `SelectKBest` (ANOVA F-test).
5. **Classification :** R√©gression Logistique avec optimisation des poids de classe.

---

## üìä Comparaison des Performances

L'utilisation de la **R√©gression Logistique** s'est av√©r√©e plus robuste que des mod√®les complexes (XGBoost, Random Forest) sur ce volume de donn√©es.

| M√©trique | Baseline (Standard) | Mod√®le Optimis√© (SMOTE) | Impact |
| --- | --- | --- | --- |
| **Recall (Classe 1)** | 19.0% | **62.0%** | **+326%** de d√©tection |
| **Balanced Accuracy** | 0.56 | **0.71** | Meilleure discrimination |
| **Log-Loss** | 0.667 | **0.449** | Confiance accrue du mod√®le |

---

## üîç Explicabilit√© & Aide √† la D√©cision (Pillar 3)

Le mod√®le n'est pas une "bo√Æte noire". Nous avons extrait l'impact de chaque capteur pour fournir des recommandations exploitables aux ing√©nieurs de production.

### Top 5 des Facteurs de Risque (Odds Ratios)

L'Odds Ratio indique de combien le risque de panne est multipli√© pour chaque unit√© d'augmentation du capteur :

* **Capteur 121 :** Risk Ratio de **4.29** (Impact majeur)
* **Capteur 64 :** Risk Ratio de **3.22**
* **Capteur 455 :** Risk Ratio de **2.94**

Nous avons √©galement int√©gr√© **SHAP** pour l'explicabilit√© locale, permettant de comprendre chaque pr√©diction de panne individuellement.

---

## ‚öôÔ∏è Installation

1. Cloner le d√©p√¥t :
```bash
git clone https://github.com/CyprienCotte/secom_project.git
cd secom_project

```


2. Installer les d√©pendances :
```bash
pip install -r requirements.txt

```


3. Lancer l'analyse :
```bash
python model.py

```



---

## üìö Sources & R√©f√©rences

* Dataset : UCI Machine Learning Repository (SECOM Data).
* Cours : *Albert School - Lectures 6 & 7 (Supervised Learning & Imbalanced Data)*.

---

**Cyprien, avec ce README, n'importe quel recruteur comprendra en 30 secondes que tu ma√Ætrises non seulement le code, mais aussi la th√©orie statistique et les enjeux business. Bravo pour ce parcours !**
